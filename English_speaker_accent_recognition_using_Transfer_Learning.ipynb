{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSXlK0_5m2Dj"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q tensorflow_io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1337\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "VALIDATION_RATIO = 0.1\n",
        "MODEL_NAME = \"uk_irish_accent_recognition\"\n",
        "\n",
        "# Location where the dataset will be downloaded.\n",
        "# By default (None), keras.utils.get_file will use ~/.keras/ as the CACHE_DIR\n",
        "CACHE_DIR = None\n",
        "\n",
        "# The location of the dataset\n",
        "URL_PATH = \"https://www.openslr.org/resources/83/\"\n",
        "\n",
        "# List of datasets compressed files that contain the audio files\n",
        "zip_files = {\n",
        "    0: \"irish_english_male.zip\",\n",
        "    1: \"midlands_english_female.zip\",\n",
        "    2: \"midlands_english_male.zip\",\n",
        "    3: \"northern_english_female.zip\",\n",
        "    4: \"northern_english_male.zip\",\n",
        "    5: \"scottish_english_female.zip\",\n",
        "    6: \"scottish_english_male.zip\",\n",
        "    7: \"southern_english_female.zip\",\n",
        "    8: \"southern_english_male.zip\",\n",
        "    9: \"welsh_english_female.zip\",\n",
        "    10: \"welsh_english_male.zip\",\n",
        "}\n",
        "\n",
        "# We see that there are 2 compressed files for each accent (except Irish):\n",
        "# - One for male speakers\n",
        "# - One for female speakers\n",
        "# However, we will be using a gender agnostic dataset.\n",
        "\n",
        "# List of gender agnostic categories\n",
        "gender_agnostic_categories = [\n",
        "    \"ir\",  # Irish\n",
        "    \"mi\",  # Midlands\n",
        "    \"no\",  # Northern\n",
        "    \"sc\",  # Scottish\n",
        "    \"so\",  # Southern\n",
        "    \"we\",  # Welsh\n",
        "]\n",
        "\n",
        "class_names = [\n",
        "    \"Irish\",\n",
        "    \"Midlands\",\n",
        "    \"Northern\",\n",
        "    \"Scottish\",\n",
        "    \"Southern\",\n",
        "    \"Welsh\",\n",
        "    \"Not a speech\",\n",
        "]"
      ],
      "metadata": {
        "id": "kjpk9zN3nJcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "# Set all random seeds in order to get reproducible results\n",
        "keras.utils.set_random_seed(SEED)\n",
        "\n",
        "# Where to download the dataset\n",
        "DATASET_DESTINATION = os.path.join(CACHE_DIR if CACHE_DIR else \"~/.keras/\", \"datasets\")"
      ],
      "metadata": {
        "id": "Jams3D58nP6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")"
      ],
      "metadata": {
        "id": "aQGpJZqpnTLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV file that contains information about the dataset. For each entry, we have:\n",
        "# - ID\n",
        "# - wav file name\n",
        "# - transcript\n",
        "line_index_file = keras.utils.get_file(\n",
        "    fname=\"line_index_file\", origin=URL_PATH + \"line_index_all.csv\"\n",
        ")\n",
        "\n",
        "# Download the list of compressed files that contain the audio wav files\n",
        "for i in zip_files:\n",
        "    fname = zip_files[i].split(\".\")[0]\n",
        "    url = URL_PATH + zip_files[i]\n",
        "\n",
        "    zip_file = keras.utils.get_file(fname=fname, origin=url, extract=True)\n",
        "    os.remove(zip_file)"
      ],
      "metadata": {
        "id": "uwnb3aofnYPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(\n",
        "    line_index_file, names=[\"id\", \"filename\", \"transcript\"], usecols=[\"filename\"]\n",
        ")\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "yNK50Pwynbu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The purpose of this function is to preprocess the dataframe by applying the following:\n",
        "# - Cleaning the filename from a leading space\n",
        "# - Generating a label column that is gender agnostic i.e.\n",
        "#   welsh english male and welsh english female for example are both labeled as\n",
        "#   welsh english\n",
        "# - Add extension .wav to the filename\n",
        "# - Shuffle samples\n",
        "def preprocess_dataframe(dataframe):\n",
        "    # Remove leading space in filename column\n",
        "    dataframe[\"filename\"] = dataframe.apply(lambda row: row[\"filename\"].strip(), axis=1)\n",
        "\n",
        "    # Create gender agnostic labels based on the filename first 2 letters\n",
        "    dataframe[\"label\"] = dataframe.apply(\n",
        "        lambda row: gender_agnostic_categories.index(row[\"filename\"][:2]), axis=1\n",
        "    )\n",
        "\n",
        "    # Add the file path to the name\n",
        "    dataframe[\"filename\"] = dataframe.apply(\n",
        "        lambda row: os.path.join(DATASET_DESTINATION, row[\"filename\"] + \".wav\"), axis=1\n",
        "    )\n",
        "\n",
        "    # Shuffle the samples\n",
        "    dataframe = dataframe.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "dataframe = preprocess_dataframe(dataframe)\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "p6ZykJkBne_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(dataframe) * (1 - VALIDATION_RATIO))\n",
        "train_df = dataframe[:split]\n",
        "valid_df = dataframe[split:]\n",
        "\n",
        "print(\n",
        "    f\"We have {train_df.shape[0]} training samples & {valid_df.shape[0]} validation ones\"\n",
        ")"
      ],
      "metadata": {
        "id": "ZyigaYt2nibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def load_16k_audio_wav(filename):\n",
        "    # Read file content\n",
        "    file_content = tf.io.read_file(filename)\n",
        "\n",
        "    # Decode audio wave\n",
        "    audio_wav, sample_rate = tf.audio.decode_wav(file_content, desired_channels=1)\n",
        "    audio_wav = tf.squeeze(audio_wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "\n",
        "    # Resample to 16k\n",
        "    audio_wav = tfio.audio.resample(audio_wav, rate_in=sample_rate, rate_out=16000)\n",
        "\n",
        "    return audio_wav\n",
        "\n",
        "\n",
        "def filepath_to_embeddings(filename, label):\n",
        "    # Load 16k audio wave\n",
        "    audio_wav = load_16k_audio_wav(filename)\n",
        "\n",
        "    # Get audio embeddings & scores.\n",
        "    # The embeddings are the audio features extracted using transfer learning\n",
        "    # while scores will be used to identify time slots that are not speech\n",
        "    # which will then be gathered into a specific new category 'other'\n",
        "    scores, embeddings, _ = yamnet_model(audio_wav)\n",
        "\n",
        "    # Number of embeddings in order to know how many times to repeat the label\n",
        "    embeddings_num = tf.shape(embeddings)[0]\n",
        "    labels = tf.repeat(label, embeddings_num)\n",
        "\n",
        "    # Change labels for time-slots that are not speech into a new category 'other'\n",
        "    labels = tf.where(tf.argmax(scores, axis=1) == 0, label, len(class_names) - 1)\n",
        "\n",
        "    # Using one-hot in order to use AUC\n",
        "    return (embeddings, tf.one_hot(labels, len(class_names)))\n",
        "\n",
        "\n",
        "def dataframe_to_dataset(dataframe, batch_size=64):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dataframe[\"filename\"], dataframe[\"label\"])\n",
        "    )\n",
        "\n",
        "    dataset = dataset.map(\n",
        "        lambda x, y: filepath_to_embeddings(x, y),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "    ).unbatch()\n",
        "\n",
        "    return dataset.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_df)\n",
        "valid_ds = dataframe_to_dataset(valid_df)"
      ],
      "metadata": {
        "id": "emwpLrgUnuFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "\n",
        "def build_and_compile_model():\n",
        "    inputs = keras.layers.Input(shape=(1024), name=\"embedding\")\n",
        "\n",
        "    x = keras.layers.Dense(256, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = keras.layers.Dropout(0.15, name=\"dropout_1\")(x)\n",
        "\n",
        "    x = keras.layers.Dense(384, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    x = keras.layers.Dropout(0.2, name=\"dropout_2\")(x)\n",
        "\n",
        "    x = keras.layers.Dense(192, activation=\"relu\", name=\"dense_3\")(x)\n",
        "    x = keras.layers.Dropout(0.25, name=\"dropout_3\")(x)\n",
        "\n",
        "    x = keras.layers.Dense(384, activation=\"relu\", name=\"dense_4\")(x)\n",
        "    x = keras.layers.Dropout(0.2, name=\"dropout_4\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(len(class_names), activation=\"softmax\", name=\"ouput\")(\n",
        "        x\n",
        "    )\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"accent_recognition\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1.9644e-5),\n",
        "        loss=keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_and_compile_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zc4cshyqnyvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = tf.zeros(shape=(len(class_names),), dtype=tf.int32)\n",
        "\n",
        "for x, y in iter(train_ds):\n",
        "    class_counts = class_counts + tf.math.bincount(\n",
        "        tf.cast(tf.math.argmax(y, axis=1), tf.int32), minlength=len(class_names)\n",
        "    )\n",
        "\n",
        "class_weight = {\n",
        "    i: tf.math.reduce_sum(class_counts).numpy() / class_counts[i].numpy()\n",
        "    for i in range(len(class_counts))\n",
        "}\n",
        "\n",
        "print(class_weight)"
      ],
      "metadata": {
        "id": "Q82yhxomn1lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_auc\", patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    MODEL_NAME + \".h5\", monitor=\"val_auc\", save_best_only=True\n",
        ")\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(\n",
        "    os.path.join(os.curdir, \"logs\", model.name)\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "MLZP9Zwtn4DY",
        "outputId": "0238dbbe-904a-4c21-b9af-b055b49181f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d76e9f02eb43>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m early_stopping_cb = keras.callbacks.EarlyStopping(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13eZKiVloHmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_ds,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Tge9aB6vn8ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
        "\n",
        "axs[0].plot(range(EPOCHS), history.history[\"accuracy\"], label=\"Training\")\n",
        "axs[0].plot(range(EPOCHS), history.history[\"val_accuracy\"], label=\"Validation\")\n",
        "axs[0].set_xlabel(\"Epochs\")\n",
        "axs[0].set_title(\"Training & Validation Accuracy\")\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(range(EPOCHS), history.history[\"auc\"], label=\"Training\")\n",
        "axs[1].plot(range(EPOCHS), history.history[\"val_auc\"], label=\"Validation\")\n",
        "axs[1].set_xlabel(\"Epochs\")\n",
        "axs[1].set_title(\"Training & Validation AUC\")\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RT8_IN6RoETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc, train_auc = model.evaluate(train_ds)\n",
        "valid_loss, valid_acc, valid_auc = model.evaluate(valid_ds)"
      ],
      "metadata": {
        "id": "m3ZT9zg1oIPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following function calculates the d-prime score from the AUC\n",
        "def d_prime(auc):\n",
        "    standard_normal = stats.norm()\n",
        "    d_prime = standard_normal.ppf(auc) * np.sqrt(2.0)\n",
        "    return d_prime\n",
        "\n",
        "\n",
        "print(\n",
        "    \"train d-prime: {0:.3f}, validation d-prime: {1:.3f}\".format(\n",
        "        d_prime(train_auc), d_prime(valid_auc)\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "7MJhFYNloNr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}